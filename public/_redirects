
# Netlify redirects file
# Redirect crawlers to SEO proxy edge function
# Bot detection redirects - send crawlers to SEO proxy
/*  https://yxsnoncplnzekfwaknxb.supabase.co/functions/v1/seo-proxy?path=:splat  200  User-Agent: *bot*
/*  https://yxsnoncplnzekfwaknxb.supabase.co/functions/v1/seo-proxy?path=:splat  200  User-Agent: *crawler*
/*  https://yxsnoncplnzekfwaknxb.supabase.co/functions/v1/seo-proxy?path=:splat  200  User-Agent: *spider*
/*  https://yxsnoncplnzekfwaknxb.supabase.co/functions/v1/seo-proxy?path=:splat  200  User-Agent: *frog*
/*  https://yxsnoncplnzekfwaknxb.supabase.co/functions/v1/seo-proxy?path=:splat  200  User-Agent: *screaming*
/*  https://yxsnoncplnzekfwaknxb.supabase.co/functions/v1/seo-proxy?path=:splat  200  User-Agent: *semrush*
/*  https://yxsnoncplnzekfwaknxb.supabase.co/functions/v1/seo-proxy?path=:splat  200  User-Agent: *ahrefs*

# Static files - serve directly first
/sitemap.xml /sitemap.xml 200
/robots.txt /robots.txt 200
/favicon.ico /favicon.ico 200
*.png /lovable-uploads/:splat 200
*.jpg /lovable-uploads/:splat 200
*.jpeg /lovable-uploads/:splat 200
*.svg /lovable-uploads/:splat 200

# API routes (if any)
/api/* /api/:splat 200

# React Router fallback for all other routes (non-crawlers)
/* /index.html 200
